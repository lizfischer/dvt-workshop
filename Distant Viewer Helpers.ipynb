{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a batch of videos\n",
    "\n",
    "This code runs DVT on all the videos in a particular directory and produces a website output in a folder called full-data-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"clips/trailers/\"\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".mp4\"):\n",
    "        print(\"Running file: \" + file)\n",
    "        !python -m dvt video-viz {directory + file} --dirout full-data-output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m dvt video-viz clips/trailers/Official_Trailer_TROUBLE_WITH_THE_CURVE-Clint_Eastwood_Justin_Timberlake.mp4 --dirout full-data-output\n",
    "!python -m dvt video-viz clips/trailers/Terminator_Dark_Fate.mp4  --dirout full-data-output\n",
    "!python -m dvt video-viz clips/trailers/The_Terminator_1984_Official_Trailer_Arnold_Schwarzenegger.mp4  --dirout full-data-output\n",
    "!python -m dvt video-viz clips/protest/anti_vietnam_war_protest.mp4  --dirout full-data-output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile JSON data to CSV\n",
    "To make it easy to read the numeric outputs from DVT, this code reads the JSON outout for every video and pulls some potentially interesting features together into one CSV. It draws video name, number of shots, number of shots with people, objects detected, and people detected more or less straight from the JSON; it calculates the avgerage number of people per shot, most common shot length, and average shot duration in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, os\n",
    "from statistics import mode\n",
    "\n",
    "# Data directory containing a JSON file for each video\n",
    "directory = \"full-data-output/data/\"\n",
    "\n",
    "# Output will be written to AllOutputs.csv\n",
    "with open(\"AllOutputs.csv\", 'w') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=\",\") \n",
    "    \n",
    "    # Write header row\n",
    "    writer.writerow([\"Video name\", \"Num shots\", \"Num shots with people\", \"Avg people per shot\", \"Most common shot length\",\n",
    "                            \"Avg shot duration (in seconds)\", \"Objects detected\", \"People detected\"])\n",
    "    \n",
    "    # Loop over JSON files\n",
    "    for file in os.listdir(directory):\n",
    "        if file != \"toc.json\": # skip the table of contents file\n",
    "            with open(directory + file, 'r') as videojson:\n",
    "                data = json.load(videojson)\n",
    "                name = data[\"meta\"][0][\"input_filename\"]\n",
    "                num_shots = len(data[\"cut\"])\n",
    "\n",
    "\n",
    "                # Find most common shot length\n",
    "                shot_lengths = []\n",
    "                for l in data[\"length\"]:\n",
    "                    shot_lengths.append(l[\"shot_length\"])\n",
    "                try:\n",
    "                    mode_shot_length = mode(shot_lengths)\n",
    "                except:\n",
    "                    mode_shot_length = \"\"\n",
    "\n",
    "\n",
    "                # Counting people and objects\n",
    "                checked_frames = []\n",
    "                num_shots_peopled = 0\n",
    "                objects = []\n",
    "                people_per_shot = {}\n",
    "                for obj in data[\"obj\"]:\n",
    "                    if obj[\"frame\"] in checked_frames:\n",
    "                        if obj[\"category\"] == \"person\":\n",
    "                            people_per_shot[obj[\"frame\"]] += 1\n",
    "                    else:\n",
    "                        # Count frames with people\n",
    "                        if obj[\"category\"] == \"person\":\n",
    "                            num_shots_peopled += 1\n",
    "                            people_per_shot[obj[\"frame\"]] = 1\n",
    "                        else:\n",
    "                            people_per_shot[obj[\"frame\"]] = 0\n",
    "                        checked_frames.append(obj[\"frame\"])\n",
    "\n",
    "                    # Add objects\n",
    "                    if obj[\"category\"] != \"person\" and obj[\"category\"] not in objects:\n",
    "                        objects.append(obj[\"category\"])\n",
    "\n",
    "                avg_people_per_shot = sum(people_per_shot.values()) / len(people_per_shot.values())\n",
    "\n",
    "                # Faces detected\n",
    "                people = []\n",
    "                if \"people\" in data:\n",
    "                    for person in data[\"people\"]:\n",
    "                        if person[\"person\"] not in people:\n",
    "                            people.append(person[\"person\"])\n",
    "\n",
    "                # Calculate average shot length in seconds\n",
    "                shot_durations = []\n",
    "                for shot in data[\"cut\"]:\n",
    "                    shot_durations.append(shot[\"frame_end\"]-shot[\"frame_start\"])\n",
    "                avg_shot_duration = (sum(shot_durations)/len(shot_durations))/data[\"meta\"][0][\"fps\"]\n",
    "\n",
    "\n",
    "                writer.writerow([name, num_shots, num_shots_peopled, avg_people_per_shot, mode_shot_length,\n",
    "                            avg_shot_duration, '|'.join(objects), '|'.join(people)])             \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add face data to output site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "\u001b[KProcessing annotators:  |#######################         | 11/15Killed\n",
      "Using TensorFlow backend.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "\u001b[KProcessing annotators:  |################################| 15/15\n",
      "\u001b[?25h\u001b[?25lProgress: Killed\n",
      "Using TensorFlow backend.\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n",
      "\u001b[KProcessing annotators:  |################################| 15/15\n",
      "\u001b[?25h\u001b[?25lProgress: Killed\n"
     ]
    }
   ],
   "source": [
    "# Generate data site\n",
    "!python -m dvt video-viz face-recognition-demo/Speed_Clip_Faces.mp4 --path-to-faces=face-recognition-demo/faces/speed/clip_faces --dirout face-recognition-demo/dvt-output-data\n",
    "!python -m dvt video-viz face-recognition-demo/Speed_Hard_Faces.mp4 --path-to-faces=face-recognition-demo/faces/speed/hard_faces --dirout face-recognition-demo/dvt-output-data\n",
    "!python -m dvt video-viz face-recognition-demo/Speed_Outside_Faces.mp4 --path-to-faces=face-recognition-demo/faces/speed/outside_faces --dirout face-recognition-demo/dvt-output-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/sharedfolder\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'face-recognition-demo/dvt-output-data/data/Speed_Outside_Faces.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f9486c755add>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"face-recognition-demo/dvt-output-data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"data/Speed_Outside_Faces.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mvideojson\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'face-recognition-demo/dvt-output-data/data/Speed_Outside_Faces.json'"
     ]
    }
   ],
   "source": [
    "import json, cv2, os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(os.getcwd())\n",
    "directory = \"face-recognition-demo/dvt-output-data/\"\n",
    "with open(directory + \"data/Speed_Outside_Faces.json\", 'r') as file:\n",
    "    videojson = json.load(file)\n",
    "\n",
    "people = videojson[\"people\"]\n",
    "\n",
    "filename = videojson[\"meta\"][0][\"input_filename\"]\n",
    "outdir = directory + \"img/\" + filename + \"/faces\"\n",
    "os.mkdir(outdir)\n",
    "\n",
    "for person in people:\n",
    "    frame_num = person[\"frame\"]\n",
    "    frame_img = directory + \"img/\" + filename + \"/frames/frame-\" + str(frame_num).zfill(6) + \".png\"\n",
    "    img = cv2.imread(frame_img)\n",
    "    cv2.rectangle(img, (person[\"left\"], person[\"top\"]), (person[\"right\"], person[\"bottom\"]), (24, 127, 245), 3)\n",
    "    cv2.putText(img, person[\"person\"], (person[\"left\"], person[\"bottom\"] + 25), cv2.FONT_HERSHEY_SIMPLEX, 1, (24, 127, 245))\n",
    "\n",
    "    print(outfile)\n",
    "    cv2.imwrite(outdir + \"/frame-\" + str(frame_num).zfill(6) + \".png\", img)\n",
    "    #cv2.imshow(\"img\", img)\n",
    "    plt.imshow(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
